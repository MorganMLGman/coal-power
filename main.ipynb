{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Combustion analysis in a coal-fired power plant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from scipy.io import loadmat\n",
    "from scipy.signal import find_peaks, findfreqs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_FILE = \"a08r.mat\"\n",
    "ARRAY_NAME = \"a08r\"\n",
    "SPS = 8192 # Samples per second"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### findMaximum\n",
    "Funkcja służąca do wyszukiwanie punktów maksimum w otrzymanych danych\n",
    "\n",
    "Parametry:\n",
    "- data: dataFrame z danymi, cały niezmodyfikowany\n",
    "- column: nazwa kolumny w której chcemy szukać\n",
    "- width: minimalna szerokość (x) piku\n",
    "- distance: minimlna odległość (x) pomiędzy szukanymi punktami\n",
    "- threshold: minimlna/maksymalna odległość (y) pomiędzy szukanymi punktami\n",
    "- prominence: eeee, to nie wiem, ale czasami jak większe to pomaga eliminować podwójne punkty\n",
    "  \n",
    "Zwraca listę z punktami maksimum\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def findMaximums(data: pd.DataFrame, column: str, width: int = 10, distance: int = SPS*45, threshold: list = None, prominence: float = 0.1) -> list:\n",
    "    \"\"\"Funkcja służąca do wyszukiwanie punktów maksimum w otrzymanych danych\n",
    "\n",
    "    Args:\n",
    "        data (pd.DataFrame): dataFrame z danymi, cały niezmodyfikowany\n",
    "        column (str): nazwa kolumny w której chcemy szukać\n",
    "        width (int, optional): minimalna szerokość (x) piku. Defaults to 10.\n",
    "        distance (int, optional): minimlna odległość (x) pomiędzy szukanymi punktami. Defaults to SPS*45.\n",
    "        threshold (list, optional): minimlna/maksymalna odległość (y) pomiędzy szukanymi punktami. Defaults to None.\n",
    "        prominence (float, optional): eeee, to nie wiem, ale czasami jak większe to pomaga eliminować podwójne punkty. Defaults to 0.1.\n",
    "\n",
    "    Returns:\n",
    "        list: Zwraca listę z punktami maksimum\n",
    "    \"\"\"\n",
    "    ret = []\n",
    "    ret = find_peaks(data[column], width=width, distance=distance, threshold=threshold, prominence=prominence)[0].tolist()\n",
    "    return ret  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### dataSplit\n",
    "Funkcja służąca do podziału danych na podzbiory, według podanej listy podziału. Przykładowo dla punktów podziału 1, 2, 3, zwraca przedziały [1, 2], [2, 3]\n",
    "\n",
    "Parametry:\n",
    "- data: dataFrame z danymi, cały niezmodyfikowany\n",
    "- spliter: lista, wykorzystywana do podziału\n",
    "- channel: nazwa kanału, który ma zostać zpisany, `all` jeżeli wszystkie\n",
    "  \n",
    "Zwraca dataFrame z przedziałami"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dataSplit(data: pd.DataFrame, spliter: list, channel: str = \"all\") -> pd.DataFrame:\n",
    "    \"\"\"Funkcja służąca do podziału danych na podzbiory, według podanej listy podziału. Przykładowo dla punktów podziału 1, 2, 3, zwraca przedziały [1, 2], [2, 3]\n",
    "\n",
    "    Args:\n",
    "        data (pd.DataFrame): dataFrame z danymi, cały niezmodyfikowany\n",
    "        spliter (list): lista, wykorzystywana do podziału\n",
    "        channel (str): nazwa kanału, który ma zostać zpisany, `all` jeżeli wszystkie\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: Zwraca dataFrame z przedziałami\n",
    "    \"\"\"\n",
    "    ret = pd.DataFrame()\n",
    "    num_of_buckets = len(spliter) - 1\n",
    "    keys = [f\"bucket{i}\" for i in range(num_of_buckets)]\n",
    "    tmp = []\n",
    "    \n",
    "    if \"all\" == channel:\n",
    "        for item in range(num_of_buckets):\n",
    "            tmp.append(data[spliter[item]:spliter[item + 1]])\n",
    "        ret = pd.concat(tmp, keys=keys)\n",
    "        \n",
    "    elif channel in data.columns:\n",
    "        for item in range(num_of_buckets):\n",
    "            tmp.append(data[channel][spliter[item]:spliter[item + 1]])\n",
    "        ret = pd.concat(tmp, keys=keys)\n",
    "        \n",
    "    else:\n",
    "        ret = None\n",
    "        \n",
    "    return ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        ch1       ch2       ch3       ch4       ch5\n",
      "0  0.049816  0.179095  0.170236  0.177783  0.679478\n",
      "1  0.048832  0.177783  0.170236  0.177455  0.679150\n",
      "2  0.049488  0.178111  0.170236  0.177455  0.678165\n",
      "2457600\n",
      "                      ch1       ch2       ch3       ch4       ch5\n",
      "bucket0 379226   0.063269  0.265719  0.253907  0.247672  0.958707\n",
      "        379227   0.063597  0.268344  0.253907  0.247016  0.958379\n",
      "        379228   0.063925  0.267360  0.253250  0.246360  0.958051\n",
      "        379229   0.062941  0.267031  0.253579  0.247016  0.958051\n",
      "        379230   0.062941  0.267360  0.253250  0.247344  0.958051\n",
      "...                   ...       ...       ...       ...       ...\n",
      "bucket3 2378422  0.060316  0.259157  0.269000  0.262766  0.986926\n",
      "        2378423  0.060972  0.258828  0.268016  0.263750  0.985613\n",
      "        2378424  0.059660  0.259485  0.268672  0.264078  0.986269\n",
      "        2378425  0.059988  0.258828  0.269000  0.263750  0.985285\n",
      "        2378426  0.058676  0.258828  0.268672  0.264735  0.986598\n",
      "\n",
      "[1999201 rows x 5 columns]\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    \n",
    "    data = pd.DataFrame(loadmat(DATA_FILE)[ARRAY_NAME], columns=([\"ch1\", \"ch2\", \"ch3\", \"ch4\", \"ch5\"]))\n",
    "    print(data.head(3))\n",
    "    print(data[\"ch1\"].size)  \n",
    "    \n",
    "    maximums_a08r_ch5 = findMaximums(data, \"ch5\", prominence=0.4)    \n",
    "    print(dataSplit(data, maximums_a08r_ch5, \"all\"))\n",
    "    \n",
    "    # plt.figure(figsize=(15, 8))\n",
    "    # plt.plot(data[\"ch5\"], label=\"Channel 5 raw data\")\n",
    "    # plt.plot(data[\"ch5\"].rolling(SPS*3).mean(), color=\"r\", label=\"3s mean\")\n",
    "    \n",
    "    # plt.plot(maximums_a08r_ch5, [data[\"ch5\"][item] for item in maximums_a08r_ch5], \"o\", color=\"g\")\n",
    "    # plt.legend()\n",
    "    # plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "5fe9bf720a09048f895527f1e3c53a16c4c6d129a6fb078ad1d9407b5596ae09"
  },
  "kernelspec": {
   "display_name": "Python 3.10.4 ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
